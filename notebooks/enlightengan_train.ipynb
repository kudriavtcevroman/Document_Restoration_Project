{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ea9baf",
   "metadata": {},
   "source": [
    "# Обучение модели EnlightenGAN для восстановления изображений с эффектом \"засветления/затемнения\"\n",
    "Этаот Notebook демонстрирует процесс fine-tuning модели EnlightenGAN на датасете с искаженными изображениями (эффект brightness/contrast). \n",
    "\n",
    "Мы используем предобученные веса и адаптируем модель под разрешение 1024x1448. \n",
    "\n",
    "Обучение включает комбинированный loss (L1 + perceptual), мониторинг метрик (Loss, PSNR, SSIM), early stopping и сохранение чекпоинтов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5482b927",
   "metadata": {},
   "source": [
    "## Шаг 1: Настройка окружения и выбор GPU\n",
    "Выбираем свободную GPU, настраиваем PyTorch для оптимальной работы с CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Выбор GPU с максимум свободной памяти\n",
    "result = subprocess.check_output(\n",
    "    [\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"]\n",
    ").decode().strip()\n",
    "\n",
    "gpu_list = [tuple(map(int, line.split(', '))) for line in result.splitlines()]\n",
    "best_idx, max_free = max(gpu_list, key=lambda x: x[1])\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(best_idx)\n",
    "print(f\"Выбрана физическая GPU {best_idx} — свободно ~{max_free//1024} GiB\")\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Работаем на {device} ({torch.cuda.get_device_name(0)})\")\n",
    "print(f\"VRAM allocated после инициализации: {torch.cuda.memory_allocated(device)/(1024**3):.1f} GiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c58144",
   "metadata": {},
   "source": [
    "## Шаг 2: Импорт библиотек и архитектуры модели\n",
    "Импортируем необходимые библиотеки, переходим в директорию EnlightenGAN для импорта генератора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Переход в папку EnlightenGAN\n",
    "os.chdir('/home/kudriavtcevroman-10/EnlightenGAN')\n",
    "from models.networks import define_G\n",
    "os.chdir('/home/kudriavtcevroman-10')\n",
    "\n",
    "# Проверка наличия файлов\n",
    "if os.path.exists('EnlightenGAN/models/networks.py'):\n",
    "    print(\"Файл networks.py найден.\")\n",
    "else:\n",
    "    print(\"Ошибка: Файл networks.py не найден. Проверь структуру папки EnlightenGAN.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9466aed",
   "metadata": {},
   "source": [
    "## Шаг 3: Инициализация модели и perceptual loss\n",
    "Определяем опции модели, инициализируем генератор с ngf=160, загружаем предобученные веса частично, добавляем perceptual loss на VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19\n",
    "\n",
    "# Опции модели\n",
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.self_attention = False\n",
    "        self.use_norm = 1\n",
    "        self.syn_norm = False\n",
    "        self.use_avgpool = 0\n",
    "        self.tanh = False\n",
    "        self.times_residual = False\n",
    "        self.linear_add = False\n",
    "        self.latent_threshold = False\n",
    "        self.latent_norm = False\n",
    "        self.linear = False\n",
    "        self.skip = 1.0\n",
    "\n",
    "opt = Opt()\n",
    "\n",
    "# Инициализация генератора\n",
    "gpu_ids = [0] if torch.cuda.is_available() else []\n",
    "generator = define_G(input_nc=4, output_nc=3, ngf=160, which_model_netG='sid_unet_resize', norm='batch', \n",
    "                     use_dropout=False, gpu_ids=gpu_ids, skip=False, opt=opt).to(device)\n",
    "\n",
    "# Загрузка предобученных весов частично\n",
    "weights_path = 'pretrained/200_net_G_A.pth'\n",
    "if os.path.exists(weights_path):\n",
    "    checkpoint = torch.load(weights_path, map_location=device)\n",
    "    pretrained_state = checkpoint.get('params', checkpoint.get('state_dict', checkpoint))\n",
    "    \n",
    "    model_state = generator.state_dict()\n",
    "    for k, v in pretrained_state.items():\n",
    "        if k in model_state and v.size() == model_state[k].size():\n",
    "            model_state[k] = v\n",
    "    \n",
    "    generator.load_state_dict(model_state, strict=False)\n",
    "    print(\"Веса загружены частично. Новые слои дообучатся за 3-5 эпох.\")\n",
    "else:\n",
    "    print(\"Предобученные веса не найдены. Модель обучится с нуля.\")\n",
    "\n",
    "# Perceptual loss на VGG19\n",
    "vgg = vgg19(pretrained=True).features.to(device).eval()\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def perceptual_loss(output, clean):\n",
    "    def get_features(x):\n",
    "        return vgg[:23](x)  # conv4_4\n",
    "    return nn.L1Loss()(get_features(output), get_features(clean))\n",
    "\n",
    "print(f\"Модель готова с ngf=160 и perceptual loss. VRAM: {torch.cuda.memory_allocated(device)/1024:.1f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d618b4",
   "metadata": {},
   "source": [
    "## Шаг 4: Подготовка датасета\n",
    "Определяем кастомный датасет для distorted (color + gray) / clean изображений, с трансформацией на разрешение 1024x1448."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7af8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кастомный трансформер с padding\n",
    "class PaddedResize:\n",
    "    def __init__(self, size=(1024, 1448), div_factor=8):\n",
    "        self.size = size\n",
    "        self.div_factor = div_factor\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.Resize(self.size, interpolation=Image.LANCZOS)(img)\n",
    "        w, h = img.size\n",
    "        pad_w = (self.div_factor - w % self.div_factor) % self.div_factor\n",
    "        pad_h = (self.div_factor - h % self.div_factor) % self.div_factor\n",
    "        if pad_w != 0 or pad_h != 0:\n",
    "            img = transforms.Pad((0, 0, pad_w, pad_h), fill=0)(img)\n",
    "        return img\n",
    "\n",
    "# Трансформации\n",
    "transform = transforms.Compose([\n",
    "    PaddedResize(size=(1024, 1448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Кастомный датасет\n",
    "class BrightnessContrastDataset(Dataset):\n",
    "    def __init__(self, distorted_dir, clean_dir, transform=None):\n",
    "        self.distorted_images = sorted(os.listdir(distorted_dir))\n",
    "        self.clean_images = sorted(os.listdir(clean_dir))\n",
    "        self.distorted_dir = distorted_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.distorted_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dist_color = Image.open(os.path.join(self.distorted_dir, self.distorted_images[idx])).convert('RGB')\n",
    "        dist_gray = dist_color.convert('L')\n",
    "        clean = Image.open(os.path.join(self.clean_dir, self.clean_images[idx])).convert('RGB')\n",
    "        if self.transform:\n",
    "            dist_color = self.transform(dist_color)\n",
    "            dist_gray = transforms.Compose([transforms.Grayscale(num_output_channels=1), self.transform])(dist_color)\n",
    "            clean = self.transform(clean)\n",
    "        return dist_color, dist_gray, clean\n",
    "\n",
    "# Создание датасетов и лоадеров\n",
    "train_dataset = BrightnessContrastDataset('brightness_contrast/train/distorted', 'brightness_contrast/train/clean', transform=transform)\n",
    "val_dataset = BrightnessContrastDataset('brightness_contrast/val/distorted', 'brightness_contrast/val/clean', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc358ad",
   "metadata": {},
   "source": [
    "## Шаг 5: Настройка обучения\n",
    "Определяем combined loss (L1 + perceptual), метрики, оптимизатор (AdamW), scheduler и early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Комбинированный loss\n",
    "l1_loss = nn.L1Loss()\n",
    "def combined_loss(output, clean):\n",
    "    return 0.7 * l1_loss(output, clean) + 0.3 * perceptual_loss(output, clean)\n",
    "\n",
    "# Метрики\n",
    "psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "# Оптимизатор и scaler\n",
    "optimizer = AdamW(generator.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "best_val_psnr = -float('inf')\n",
    "\n",
    "# Директория для чекпоинтов\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "checkpoint_path = 'checkpoints/enlightengan_bc_ep{}.pth'\n",
    "\n",
    "# Списки для метрик\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "train_ssims, val_ssims = [], []\n",
    "\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709632ea",
   "metadata": {},
   "source": [
    "## Шаг 6: Цикл обучения\n",
    "Обучаем модель с mixed precision, мониторим метрики, сохраняем чекпоинты и применяем early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    generator.train()\n",
    "    train_loss = train_psnr = train_ssim = 0.0\n",
    "\n",
    "    for distorted_color, distorted_gray, clean in tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [train]\"):\n",
    "        distorted_color = distorted_color.to(device, non_blocking=True)\n",
    "        distorted_gray = distorted_gray.to(device, non_blocking=True)\n",
    "        clean = clean.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type='cuda'):\n",
    "            output = generator(distorted_color, distorted_gray)\n",
    "            loss = combined_loss(output, clean)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            train_psnr += psnr_metric(output, clean).item()\n",
    "            train_ssim += ssim_metric(output, clean).item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_psnr = train_psnr / len(train_loader)\n",
    "    avg_train_ssim = train_ssim / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_psnrs.append(avg_train_psnr)\n",
    "    train_ssims.append(avg_train_ssim)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Валидация\n",
    "    generator.eval()\n",
    "    val_loss = val_psnr = val_ssim = 0.0\n",
    "    with torch.no_grad():\n",
    "        for distorted_color, distorted_gray, clean in tqdm(val_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [val]\"):\n",
    "            distorted_color = distorted_color.to(device, non_blocking=True)\n",
    "            distorted_gray = distorted_gray.to(device, non_blocking=True)\n",
    "            clean = clean.to(device, non_blocking=True)\n",
    "            with autocast(device_type='cuda'):\n",
    "                output = generator(distorted_color, distorted_gray)\n",
    "                val_loss += combined_loss(output, clean).item()\n",
    "                val_psnr += psnr_metric(output, clean).item()\n",
    "                val_ssim += ssim_metric(output, clean).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = val_psnr / len(val_loader)\n",
    "    avg_val_ssim = val_ssim / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_psnrs.append(avg_val_psnr)\n",
    "    val_ssims.append(avg_val_ssim)\n",
    "\n",
    "    print(f\"\\nЭпоха {epoch+1:02d} | Train Loss: {avg_train_loss:.5f} | Val Loss: {avg_val_loss:.5f} | \"\n",
    "          f\"Val PSNR: {avg_val_psnr:.2f} dB | Val SSIM: {avg_val_ssim:.4f} | Время: {time.time() - start_time:.2f} с | \"\n",
    "          f\"VRAM: {torch.cuda.memory_allocated(device)/1024:.1f} MiB\")\n",
    "\n",
    "    # Сохранение чекпоинта\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': generator.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_psnr': best_val_psnr,\n",
    "    }, checkpoint_path.format(epoch+1))\n",
    "    print(f\"Чекпоинт сохранён для эпохи {epoch+1}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_psnr > best_val_psnr:\n",
    "        best_val_psnr = avg_val_psnr\n",
    "        torch.save(generator.state_dict(), \"checkpoints/enlightengan_best_psnr.pth\")\n",
    "        print(\"    → Лучшая модель сохранена!\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"    → Нет улучшения ({early_stop_counter}/{patience})\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping после {patience} эпох без улучшения.\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Fine-tuning EnlightenGAN завершён\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5d3c8",
   "metadata": {},
   "source": [
    "## Шаг 7: Сохранение финальной модели\n",
    "Сохраняем обученные веса для дальнейшего использования в инференсе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2044c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'finetuned_enlightengan.pth')\n",
    "print(\"Финальная модель сохранена как finetuned_enlightengan.pth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b408d",
   "metadata": {},
   "source": [
    "## Шаг 8: Визуализация метрик\n",
    "Строим графики для анализа сходимости и проверки на переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48afa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "axs[0].plot(range(1, len(train_losses)+1), train_losses, label='Train Loss', marker='o')\n",
    "axs[0].plot(range(1, len(val_losses)+1), val_losses, label='Val Loss', marker='o')\n",
    "axs[0].set_title('Loss over Epochs')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].plot(range(1, len(train_psnrs)+1), train_psnrs, label='Train PSNR', marker='o')\n",
    "axs[1].plot(range(1, len(val_psnrs)+1), val_psnrs, label='Val PSNR', marker='o')\n",
    "axs[1].set_title('PSNR over Epochs')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('PSNR (dB)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "axs[2].plot(range(1, len(train_ssims)+1), train_ssims, label='Train SSIM', marker='o')\n",
    "axs[2].plot(range(1, len(val_ssims)+1), val_ssims, label='Val SSIM', marker='o')\n",
    "axs[2].set_title('SSIM over Epochs')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('SSIM')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('enlightengan_metrics.png')\n",
    "plt.show()\n",
    "print(\"Графики сохранены как enlightengan_metrics.png. Проверьте val на рост (PSNR >30-35 dB, SSIM >0.9 идеально для документов).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
