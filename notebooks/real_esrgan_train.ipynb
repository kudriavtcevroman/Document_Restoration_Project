{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabe0d64",
   "metadata": {},
   "source": [
    "# Обучение модели Real-ESRGAN для восстановления изображений с эффектом \"пикселизации\"\n",
    "Этот Notebook демонстрирует процесс fine-tuning модели Real-ESRGAN на датасете с искаженными изображениями (эффект пикселизации). \n",
    "\n",
    "Мы используем предобученные веса с scale=1 (без upscale, только denoising/depixelation) и адаптируем модель под разрешение 1024x1448. \n",
    "\n",
    "Обучение включает комбинированный loss (Charbonnier + perceptual), мониторинг метрик (Loss, PSNR, SSIM), early stopping и сохранение чекпоинтов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd22c6",
   "metadata": {},
   "source": [
    "## Шаг 1: Настройка окружения и выбор GPU\n",
    "Выбираем свободную GPU, настраиваем PyTorch для оптимальной работы с CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Выбор GPU\n",
    "result = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"]).decode().strip()\n",
    "gpu_list = [tuple(map(int, line.split(', '))) for line in result.splitlines()]\n",
    "best_idx, max_free = max(gpu_list, key=lambda x: x[1])\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(best_idx)\n",
    "print(f\"Выбрана GPU {best_idx} — свободно ≈{max_free//1024} GiB\")\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(device)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cceef17",
   "metadata": {},
   "source": [
    "## Шаг 2: Импорт архитектуры модели\n",
    "Переходим в директорию Real-ESRGAN, импортируем RRDBNet с попытками для стабильности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/kudriavtcevroman-10/Real-ESRGAN')\n",
    "max_attempts = 5\n",
    "attempt = 0\n",
    "success = False\n",
    "while attempt < max_attempts and not success:\n",
    "    try:\n",
    "        from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "        success = True\n",
    "        print(\"Импорт удался на попытке\", attempt + 1)\n",
    "    except ImportError as e:\n",
    "        attempt += 1\n",
    "        print(f\"Ошибка на попытке {attempt}: {e}. Повтор через 2 сек...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "if not success:\n",
    "    raise ImportError(\"Импорт не удался после max_attempts попыток. Проверьте установку basicsr или зависимости.\")\n",
    "os.chdir('/home/kudriavtcevroman-10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c15cf5",
   "metadata": {},
   "source": [
    "## Шаг 3: Инициализация модели и загрузка весов\n",
    "Инициализируем RRDBNet с параметрами для depixelation (scale=1), загружаем предобученные веса частично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35403a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=20, num_grow_ch=32, scale=1).to(device)\n",
    "\n",
    "# Загрузка весов\n",
    "weights_path = '/home/kudriavtcevroman-10/pretrained/RealESRGAN_x4plus.pth'\n",
    "checkpoint = torch.load(weights_path, map_location=device)\n",
    "pretrained_state = checkpoint['params_ema']\n",
    "\n",
    "model_state = model.state_dict()\n",
    "for k, v in pretrained_state.items():\n",
    "    if k in model_state and v.size() == model_state[k].size():\n",
    "        model_state[k] = v\n",
    "\n",
    "model.load_state_dict(model_state, strict=False)\n",
    "print(f\"Модель на устройстве: {device}. Веса загружены частично с фильтрацией (strict=False). Новые слои дообучатся.\")\n",
    "print(f\"VRAM после модели: {torch.cuda.memory_allocated(device)/1024**3:.1f} GiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ae9a2",
   "metadata": {},
   "source": [
    "## Шаг 4: Подготовка датасета\n",
    "Определяем кастомный датасет для distorted/clean изображений, с трансформацией на разрешение 1024x1448 и padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Кастомный трансформер\n",
    "class PaddedResize:\n",
    "    def __init__(self, size=(1024, 1448), div_factor=8):\n",
    "        self.size = size\n",
    "        self.div_factor = div_factor\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.Resize(self.size, interpolation=Image.LANCZOS)(img)\n",
    "        w, h = img.size\n",
    "        pad_w = (self.div_factor - w % self.div_factor) % self.div_factor\n",
    "        pad_h = (self.div_factor - h % self.div_factor) % self.div_factor\n",
    "        if pad_w != 0 or pad_h != 0:\n",
    "            img = transforms.Pad((0, 0, pad_w, pad_h), fill=0)(img)\n",
    "        return img\n",
    "\n",
    "# Трансформации\n",
    "transform = transforms.Compose([\n",
    "    PaddedResize(size=(1024, 1448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Кастомный датасет\n",
    "class PixelationDataset(Dataset):\n",
    "    def __init__(self, distorted_dir, clean_dir, transform=None):\n",
    "        self.distorted_images = sorted(os.listdir(distorted_dir))\n",
    "        self.clean_images = sorted(os.listdir(clean_dir))\n",
    "        self.distorted_dir = distorted_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.distorted_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dist = Image.open(os.path.join(self.distorted_dir, self.distorted_images[idx])).convert('RGB')\n",
    "        clean = Image.open(os.path.join(self.clean_dir, self.clean_images[idx])).convert('RGB')\n",
    "        if self.transform:\n",
    "            dist = self.transform(dist)\n",
    "            clean = self.transform(clean)\n",
    "        return dist, clean\n",
    "\n",
    "# Датасеты и лоадеры\n",
    "train_dataset = PixelationDataset('pixelation/train/distorted', 'pixelation/train/clean', transform=transform)\n",
    "val_dataset = PixelationDataset('pixelation/val/distorted', 'pixelation/val/clean', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2bca8f",
   "metadata": {},
   "source": [
    "## Шаг 5: Настройка loss и обучения\n",
    "Определяем combined loss (Charbonnier + perceptual), метрики, оптимизатор, scheduler и early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Perceptual loss\n",
    "vgg = vgg19(pretrained=True).features.to(device).eval()\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def perceptual_loss(output, clean):\n",
    "    def get_features(x):\n",
    "        return vgg[:23](x)  # conv4_4\n",
    "    return nn.L1Loss()(get_features(output), get_features(clean))\n",
    "\n",
    "# Charbonnier loss\n",
    "def charbonnier_loss(pred, target, eps=1e-6):\n",
    "    return torch.mean(torch.sqrt((pred - target) ** 2 + eps))\n",
    "\n",
    "# Combined loss\n",
    "def combined_loss(output, clean):\n",
    "    return 0.7 * charbonnier_loss(output, clean) + 0.3 * perceptual_loss(output, clean)\n",
    "\n",
    "# Метрики\n",
    "psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "# Оптимизатор и scaler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "best_val_psnr = -float('inf')\n",
    "\n",
    "# Директория для чекпоинтов\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "checkpoint_path = 'checkpoints/real_esrgan_pix_ep{}.pth'\n",
    "\n",
    "# Списки для метрик\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "train_ssims, val_ssims = [], []\n",
    "\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfb7dd",
   "metadata": {},
   "source": [
    "## Шаг 6: Цикл обучения\n",
    "Обучаем модель с mixed precision, мониторим метрики, сохраняем чекпоинты и применяем early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38507a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = train_psnr = train_ssim = 0.0\n",
    "\n",
    "    for dist, clean in tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [train]\"):\n",
    "        dist = dist.to(device, non_blocking=True)\n",
    "        clean = clean.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type='cuda'):\n",
    "            pred = model(dist)\n",
    "            loss = combined_loss(pred, clean)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            train_psnr += psnr_metric(pred, clean).item()\n",
    "            train_ssim += ssim_metric(pred, clean).item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_psnr = train_psnr / len(train_loader)\n",
    "    avg_train_ssim = train_ssim / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_psnrs.append(avg_train_psnr)\n",
    "    train_ssims.append(avg_train_ssim)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = val_psnr = val_ssim = 0.0\n",
    "    with torch.no_grad():\n",
    "        for dist, clean in tqdm(val_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [val]\"):\n",
    "            dist = dist.to(device, non_blocking=True)\n",
    "            clean = clean.to(device, non_blocking=True)\n",
    "            with autocast(device_type='cuda'):\n",
    "                pred = model(dist)\n",
    "                val_loss += combined_loss(pred, clean).item()\n",
    "                val_psnr += psnr_metric(pred, clean).item()\n",
    "                val_ssim += ssim_metric(pred, clean).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = val_psnr / len(val_loader)\n",
    "    avg_val_ssim = val_ssim / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_psnrs.append(avg_val_psnr)\n",
    "    val_ssims.append(avg_val_ssim)\n",
    "\n",
    "    print(f\"\\nЭпоха {epoch+1:02d} | Train Loss: {avg_train_loss:.5f} | Val Loss: {avg_val_loss:.5f} | \"\n",
    "          f\"Val PSNR: {avg_val_psnr:.2f} dB | Val SSIM: {avg_val_ssim:.4f} | Время: {time.time() - start_time:.2f} с | \"\n",
    "          f\"VRAM: {torch.cuda.memory_allocated(device)/1024**3:.1f} GiB\")\n",
    "\n",
    "    # Сохранение чекпоинта\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_psnr': best_val_psnr,\n",
    "    }, checkpoint_path.format(epoch+1))\n",
    "    print(f\"Чекпоинт сохранён для эпохи {epoch+1}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_psnr > best_val_psnr:\n",
    "        best_val_psnr = avg_val_psnr\n",
    "        torch.save(model.state_dict(), \"checkpoints/real_esrgan_best_psnr.pth\")\n",
    "        print(\"    → Лучшая модель сохранена!\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"    → Нет улучшения ({early_stop_counter}/{patience})\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping после {patience} эпох без улучшения.\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Fine-tuning Real-ESRGAN завершён\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523f532",
   "metadata": {},
   "source": [
    "## Шаг 7: Сохранение финальной модели\n",
    "Сохраняем обученные веса для дальнейшего использования в инференсе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'finetuned_real_esrgan.pth')\n",
    "print(\"Финальная модель сохранена как finetuned_real_esrgan.pth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b71c7e",
   "metadata": {},
   "source": [
    "## Шаг 8: Визуализация метрик\n",
    "Строим графики для анализа сходимости и проверки на переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Loss\n",
    "axs[0].plot(range(1, len(train_losses)+1), train_losses, label='Train Loss', marker='o')\n",
    "axs[0].plot(range(1, len(val_losses)+1), val_losses, label='Val Loss', marker='o')\n",
    "axs[0].set_title('Loss over Epochs')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# PSNR\n",
    "axs[1].plot(range(1, len(train_psnrs)+1), train_psnrs, label='Train PSNR', marker='o')\n",
    "axs[1].plot(range(1, len(val_psnrs)+1), val_psnrs, label='Val PSNR', marker='o')\n",
    "axs[1].set_title('PSNR over Epochs')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('PSNR (dB)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# SSIM\n",
    "axs[2].plot(range(1, len(train_ssims)+1), train_ssims, label='Train SSIM', marker='o')\n",
    "axs[2].plot(range(1, len(val_ssims)+1), val_ssims, label='Val SSIM', marker='o')\n",
    "axs[2].set_title('SSIM over Epochs')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('SSIM')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('real_esrgan_metrics.png')\n",
    "plt.show()\n",
    "print(\"Графики сохранены как real_esrgan_metrics.png. Проверьте val на рост (PSNR >30-35 dB, SSIM >0.9 идеально для пикселизации).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
