{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43b58f9",
   "metadata": {},
   "source": [
    "# Обучение модели Restormer для восстановления изображений с эффектом \"плохой печати\"\n",
    "Этот Notebook демонстрирует процесс fine-tuning модели Restormer на датасете с искаженными изображениями (эффект плохой печати). \n",
    "\n",
    "Мы используем предобученные веса для denoising и адаптируем модель под разрешение 1024x1448. \n",
    "\n",
    "Обучение включает мониторинг метрик (Loss, PSNR, SSIM), early stopping и сохранение чекпоинтов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16bfab",
   "metadata": {},
   "source": [
    "## Шаг 1: Настройка окружения и выбор GPU\n",
    "Выбираем свободную GPU, настраиваем PyTorch для оптимальной работы с CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты и настройка\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Получение списка GPU и выбор с максимум свободной памяти\n",
    "result = subprocess.check_output(\n",
    "    [\"nvidia-smi\", \"--query-gpu=index,memory.free\", \"--format=csv,noheader,nounits\"]\n",
    ").decode().strip()\n",
    "\n",
    "gpu_list = [tuple(map(int, line.split(', '))) for line in result.splitlines()]\n",
    "best_idx, max_free = max(gpu_list, key=lambda x: x[1])\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(best_idx)\n",
    "print(f\"Выбрана GPU {best_idx} — свободно ≈{max_free//1024} GiB\")\n",
    "\n",
    "# Установка устройства и очистка кэша\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(device)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff625976",
   "metadata": {},
   "source": [
    "## Шаг 2: Загрузка модели Restormer\n",
    "Импортируем модифицированную архитектуру Restormer с gradient checkpointing для экономии VRAM, загружаем предобученные веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переход в директорию с архитектурой\n",
    "\n",
    "from restormer_arch import Restormer\n",
    "sys.path.append('/home/kudriavtcevroman-10')\n",
    "\n",
    "# Инициализация модели с checkpointing\n",
    "model = Restormer(\n",
    "    inp_channels=3,\n",
    "    out_channels=3,\n",
    "    dim=48,\n",
    "    num_blocks=[4, 6, 6, 8],\n",
    "    num_refinement_blocks=4,\n",
    "    heads=[1, 2, 4, 8],\n",
    "    ffn_expansion_factor=2.66,\n",
    "    bias=False,\n",
    "    LayerNorm_type='BiasFree',\n",
    "    dual_pixel_task=False,\n",
    "    use_checkpoint=True\n",
    ").to(device)\n",
    "\n",
    "# Загрузка предобученных весов\n",
    "weights_path = 'pretrained/gaussian_color_denoising_blind.pth'\n",
    "checkpoint = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(checkpoint.get('params', checkpoint.get('state_dict', checkpoint)), strict=True)\n",
    "\n",
    "print(\"Модель Restormer с gradient checkpointing успешно загружена\")\n",
    "print(f\"VRAM после загрузки модели: {torch.cuda.memory_allocated(device)/1024**3:.1f} GiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47297d89",
   "metadata": {},
   "source": [
    "## Шаг 3: Подготовка датасета\n",
    "Определяем кастомный класс датасета для пар distorted/clean, с трансформацией на полное разрешение 1024x1448 и padding для совместимости с моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты для датасета\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Кастомный трансформер с padding\n",
    "class PaddedResize:\n",
    "    def __init__(self, size=(1024, 1448), div_factor=8):\n",
    "        self.size = size\n",
    "        self.div_factor = div_factor\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.Resize(self.size, interpolation=Image.LANCZOS)(img)\n",
    "        w, h = img.size\n",
    "        pad_w = (self.div_factor - w % self.div_factor) % self.div_factor\n",
    "        pad_h = (self.div_factor - h % self.div_factor) % self.div_factor\n",
    "        if pad_w != 0 or pad_h != 0:\n",
    "            img = transforms.Pad((0, 0, pad_w, pad_h), fill=0)(img)\n",
    "        return img\n",
    "\n",
    "# Трансформации\n",
    "transform = transforms.Compose([\n",
    "    PaddedResize(size=(1024, 1448)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Кастомный датасет\n",
    "class BadPrintDataset(Dataset):\n",
    "    def __init__(self, distorted_dir, clean_dir, transform=None):\n",
    "        self.distorted_images = sorted(os.listdir(distorted_dir))\n",
    "        self.clean_images = sorted(os.listdir(clean_dir))\n",
    "        self.distorted_dir = distorted_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.distorted_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dist = Image.open(os.path.join(self.distorted_dir, self.distorted_images[idx])).convert('RGB')\n",
    "        clean = Image.open(os.path.join(self.clean_dir, self.clean_images[idx])).convert('RGB')\n",
    "        if self.transform:\n",
    "            dist = self.transform(dist)\n",
    "            clean = self.transform(clean)\n",
    "        return dist, clean\n",
    "\n",
    "# Создание датасетов и лоадеров\n",
    "train_dataset = BadPrintDataset('bad_print/train/distorted', 'bad_print/train/clean', transform=transform)\n",
    "val_dataset = BadPrintDataset('bad_print/val/distorted', 'bad_print/val/clean', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d1132",
   "metadata": {},
   "source": [
    "## Шаг 4: Настройка обучения\n",
    "Определяем loss (Charbonnier), метрики (PSNR, SSIM), оптимизатор (AdamW), scheduler и early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af58f1",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "# Импорты для метрик и обучения\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Кастомный loss (Charbonnier)\n",
    "def charbonnier_loss(pred, target, eps=1e-6):\n",
    "    return torch.mean(torch.sqrt((pred - target) ** 2 + eps))\n",
    "\n",
    "criterion = charbonnier_loss\n",
    "\n",
    "# Метрики\n",
    "psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "# Оптимизатор и scaler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "best_val_psnr = -float('inf')\n",
    "\n",
    "# Директория для чекпоинтов\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Списки для метрик\n",
    "train_losses, val_losses = [], []\n",
    "train_psnrs, val_psnrs = [], []\n",
    "train_ssims, val_ssims = [], []\n",
    "\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df3142",
   "metadata": {},
   "source": [
    "## Шаг 5: Цикл обучения\n",
    "Обучаем модель с mixed precision, мониторим метрики, сохраняем чекпоинты и применяем early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Цикл обучения\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = train_psnr = train_ssim = 0.0\n",
    "\n",
    "    for dist, clean in tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [train]\"):\n",
    "        dist = dist.to(device, non_blocking=True)\n",
    "        clean = clean.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type='cuda'):\n",
    "            pred = model(dist)\n",
    "            loss = criterion(pred, clean)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            train_psnr += psnr_metric(pred, clean).item()\n",
    "            train_ssim += ssim_metric(pred, clean).item()\n",
    "\n",
    "    # Средние метрики train\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_psnr = train_psnr / len(train_loader)\n",
    "    avg_train_ssim = train_ssim / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_psnrs.append(avg_train_psnr)\n",
    "    train_ssims.append(avg_train_ssim)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = val_psnr = val_ssim = 0.0\n",
    "    with torch.no_grad():\n",
    "        for dist, clean in tqdm(val_loader, desc=f\"Epoch {epoch+1:02d}/{num_epochs} [val]\"):\n",
    "            dist = dist.to(device, non_blocking=True)\n",
    "            clean = clean.to(device, non_blocking=True)\n",
    "            with autocast(device_type='cuda'):\n",
    "                pred = model(dist)\n",
    "                val_loss += criterion(pred, clean).item()\n",
    "                val_psnr += psnr_metric(pred, clean).item()\n",
    "                val_ssim += ssim_metric(pred, clean).item()\n",
    "\n",
    "    # Средние метрики val\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = val_psnr / len(val_loader)\n",
    "    avg_val_ssim = val_ssim / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_psnrs.append(avg_val_psnr)\n",
    "    val_ssims.append(avg_val_ssim)\n",
    "\n",
    "    print(f\"\\nЭпоха {epoch+1:02d} | Train Loss: {avg_train_loss:.5f} | Val Loss: {avg_val_loss:.5f} | \"\n",
    "          f\"Val PSNR: {avg_val_psnr:.2f} dB | Val SSIM: {avg_val_ssim:.4f} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Сохранение чекпоинта\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_psnr': best_val_psnr,\n",
    "    }, f\"checkpoints/restormer_badprint_ep{epoch+1}.pth\")\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_psnr > best_val_psnr:\n",
    "        best_val_psnr = avg_val_psnr\n",
    "        torch.save(model.state_dict(), \"checkpoints/restormer_badprint_best_psnr.pth\")\n",
    "        print(\"    → Новая лучшая модель сохранена!\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"    → Нет улучшения PSNR ({early_stop_counter}/{patience})\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping: переобучение обнаружено после {patience} эпох без улучшения.\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Fine-tuning Restormer завершён\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11708e2b",
   "metadata": {},
   "source": [
    "## Шаг 6: Сохранение финальной модели\n",
    "Сохраняем обученные веса для дальнейшего использования в инференсе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659fb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение финальной модели\n",
    "torch.save(model.state_dict(), 'finetuned_restormer.pth')\n",
    "print(\"Финальная модель сохранена как finetuned_restormer.pth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b214c3",
   "metadata": {},
   "source": [
    "## Шаг 7: Визуализация метрик\n",
    "Строим графики для анализа сходимости и проверки на переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Графики метрик\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Loss\n",
    "axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "axs[0].plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss', marker='o')\n",
    "axs[0].set_title('Loss over Epochs')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# PSNR\n",
    "axs[1].plot(range(1, len(train_psnrs) + 1), train_psnrs, label='Train PSNR', marker='o')\n",
    "axs[1].plot(range(1, len(val_psnrs) + 1), val_psnrs, label='Val PSNR', marker='o')\n",
    "axs[1].set_title('PSNR over Epochs')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('PSNR (dB)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# SSIM\n",
    "axs[2].plot(range(1, len(train_ssims) + 1), train_ssims, label='Train SSIM', marker='o')\n",
    "axs[2].plot(range(1, len(val_ssims) + 1), val_ssims, label='Val SSIM', marker='o')\n",
    "axs[2].set_title('SSIM over Epochs')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('SSIM')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('restormer_metrics.png')\n",
    "plt.show()\n",
    "print(\"Графики метрик сохранены как restormer_metrics.png. Проверьте на переобучение (val метрики не ухудшаются).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
